{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b599d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab7349f",
   "metadata": {},
   "source": [
    "# List of all chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390dfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "r = requests.get(\"https://openrouter.ai/api/v1/models\", timeout=30)\n",
    "r.raise_for_status()\n",
    "model_info = r.json()['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57199ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>canonical_slug</th>\n",
       "      <th>hugging_face_id</th>\n",
       "      <th>name</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>context_length</th>\n",
       "      <th>architecture</th>\n",
       "      <th>pricing</th>\n",
       "      <th>top_provider</th>\n",
       "      <th>per_request_limits</th>\n",
       "      <th>supported_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepcogito/cogito-v2-preview-llama-109b-moe</td>\n",
       "      <td>deepcogito/cogito-v2-preview-llama-109b-moe</td>\n",
       "      <td>deepcogito/cogito-v2-preview-llama-109B-MoE</td>\n",
       "      <td>Cogito V2 Preview Llama 109B</td>\n",
       "      <td>1756831568</td>\n",
       "      <td>An instruction-tuned, hybrid-reasoning Mixture...</td>\n",
       "      <td>32767</td>\n",
       "      <td>{'modality': 'text+image-&gt;text', 'input_modali...</td>\n",
       "      <td>{'prompt': '0.00000018', 'completion': '0.0000...</td>\n",
       "      <td>{'context_length': 32767, 'max_completion_toke...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, include_reasoning, logit_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepcogito/cogito-v2-preview-deepseek-671b</td>\n",
       "      <td>deepcogito/cogito-v2-preview-deepseek-671b</td>\n",
       "      <td>deepcogito/cogito-v2-preview-deepseek-671B-MoE</td>\n",
       "      <td>Deep Cogito: Cogito V2 Preview Deepseek 671B</td>\n",
       "      <td>1756830949</td>\n",
       "      <td>Cogito v2 is a multilingual, instruction-tuned...</td>\n",
       "      <td>163840</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.00000125', 'completion': '0.0000...</td>\n",
       "      <td>{'context_length': 163840, 'max_completion_tok...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, include_reasoning, logit_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen/qwen3-30b-a3b-thinking-2507</td>\n",
       "      <td>qwen/qwen3-30b-a3b-thinking-2507</td>\n",
       "      <td>Qwen/Qwen3-30B-A3B-Thinking-2507</td>\n",
       "      <td>Qwen: Qwen3 30B A3B Thinking 2507</td>\n",
       "      <td>1756399192</td>\n",
       "      <td>Qwen3-30B-A3B-Thinking-2507 is a 30B parameter...</td>\n",
       "      <td>262144</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.0000000713', 'completion': '0.00...</td>\n",
       "      <td>{'context_length': 262144, 'max_completion_tok...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, include_reasoning, logit_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x-ai/grok-code-fast-1</td>\n",
       "      <td>x-ai/grok-code-fast-1</td>\n",
       "      <td></td>\n",
       "      <td>xAI: Grok Code Fast 1</td>\n",
       "      <td>1756238927</td>\n",
       "      <td>Grok Code Fast 1 is a speedy and economical re...</td>\n",
       "      <td>256000</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.0000002', 'completion': '0.00000...</td>\n",
       "      <td>{'context_length': 256000, 'max_completion_tok...</td>\n",
       "      <td>None</td>\n",
       "      <td>[include_reasoning, logprobs, max_tokens, reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nousresearch/hermes-4-70b</td>\n",
       "      <td>nousresearch/hermes-4-70b</td>\n",
       "      <td>NousResearch/Hermes-4-70B</td>\n",
       "      <td>Nous: Hermes 4 70B</td>\n",
       "      <td>1756236182</td>\n",
       "      <td>Hermes 4 70B is a hybrid reasoning model from ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.00000009329544', 'completion': '...</td>\n",
       "      <td>{'context_length': 131072, 'max_completion_tok...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, include_reasoning, logit_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>undi95/remm-slerp-l2-13b</td>\n",
       "      <td>undi95/remm-slerp-l2-13b</td>\n",
       "      <td>Undi95/ReMM-SLERP-L2-13B</td>\n",
       "      <td>ReMM SLERP 13B</td>\n",
       "      <td>1689984000</td>\n",
       "      <td>A recreation trial of the original MythoMax-L2...</td>\n",
       "      <td>6144</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.00000045', 'completion': '0.0000...</td>\n",
       "      <td>{'context_length': 6144, 'max_completion_token...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, logit_bias, max_tokens, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>gryphe/mythomax-l2-13b</td>\n",
       "      <td>gryphe/mythomax-l2-13b</td>\n",
       "      <td>Gryphe/MythoMax-L2-13b</td>\n",
       "      <td>MythoMax 13B</td>\n",
       "      <td>1688256000</td>\n",
       "      <td>One of the highest performing and most popular...</td>\n",
       "      <td>4096</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.00000006', 'completion': '0.0000...</td>\n",
       "      <td>{'context_length': 4096, 'max_completion_token...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, logit_bias, max_tokens, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>openai/gpt-4-0314</td>\n",
       "      <td>openai/gpt-4-0314</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenAI: GPT-4 (older v0314)</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>GPT-4-0314 is the first version of GPT-4 relea...</td>\n",
       "      <td>8191</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.00003', 'completion': '0.00006',...</td>\n",
       "      <td>{'context_length': 8191, 'max_completion_token...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, logit_bias, logprobs, max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>openai/gpt-3.5-turbo</td>\n",
       "      <td>openai/gpt-3.5-turbo</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>GPT-3.5 Turbo is OpenAI's fastest model. It ca...</td>\n",
       "      <td>16385</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.0000005', 'completion': '0.00000...</td>\n",
       "      <td>{'context_length': 16385, 'max_completion_toke...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, logit_bias, logprobs, max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>openai/gpt-4</td>\n",
       "      <td>openai/gpt-4</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenAI: GPT-4</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>OpenAI's flagship model, GPT-4 is a large-scal...</td>\n",
       "      <td>8191</td>\n",
       "      <td>{'modality': 'text-&gt;text', 'input_modalities':...</td>\n",
       "      <td>{'prompt': '0.00003', 'completion': '0.00006',...</td>\n",
       "      <td>{'context_length': 8191, 'max_completion_token...</td>\n",
       "      <td>None</td>\n",
       "      <td>[frequency_penalty, logit_bias, logprobs, max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  \\\n",
       "0    deepcogito/cogito-v2-preview-llama-109b-moe   \n",
       "1     deepcogito/cogito-v2-preview-deepseek-671b   \n",
       "2               qwen/qwen3-30b-a3b-thinking-2507   \n",
       "3                          x-ai/grok-code-fast-1   \n",
       "4                      nousresearch/hermes-4-70b   \n",
       "..                                           ...   \n",
       "317                     undi95/remm-slerp-l2-13b   \n",
       "318                       gryphe/mythomax-l2-13b   \n",
       "319                            openai/gpt-4-0314   \n",
       "320                         openai/gpt-3.5-turbo   \n",
       "321                                 openai/gpt-4   \n",
       "\n",
       "                                  canonical_slug  \\\n",
       "0    deepcogito/cogito-v2-preview-llama-109b-moe   \n",
       "1     deepcogito/cogito-v2-preview-deepseek-671b   \n",
       "2               qwen/qwen3-30b-a3b-thinking-2507   \n",
       "3                          x-ai/grok-code-fast-1   \n",
       "4                      nousresearch/hermes-4-70b   \n",
       "..                                           ...   \n",
       "317                     undi95/remm-slerp-l2-13b   \n",
       "318                       gryphe/mythomax-l2-13b   \n",
       "319                            openai/gpt-4-0314   \n",
       "320                         openai/gpt-3.5-turbo   \n",
       "321                                 openai/gpt-4   \n",
       "\n",
       "                                    hugging_face_id  \\\n",
       "0       deepcogito/cogito-v2-preview-llama-109B-MoE   \n",
       "1    deepcogito/cogito-v2-preview-deepseek-671B-MoE   \n",
       "2                  Qwen/Qwen3-30B-A3B-Thinking-2507   \n",
       "3                                                     \n",
       "4                         NousResearch/Hermes-4-70B   \n",
       "..                                              ...   \n",
       "317                        Undi95/ReMM-SLERP-L2-13B   \n",
       "318                          Gryphe/MythoMax-L2-13b   \n",
       "319                                            None   \n",
       "320                                            None   \n",
       "321                                            None   \n",
       "\n",
       "                                             name     created  \\\n",
       "0                    Cogito V2 Preview Llama 109B  1756831568   \n",
       "1    Deep Cogito: Cogito V2 Preview Deepseek 671B  1756830949   \n",
       "2               Qwen: Qwen3 30B A3B Thinking 2507  1756399192   \n",
       "3                           xAI: Grok Code Fast 1  1756238927   \n",
       "4                              Nous: Hermes 4 70B  1756236182   \n",
       "..                                            ...         ...   \n",
       "317                                ReMM SLERP 13B  1689984000   \n",
       "318                                  MythoMax 13B  1688256000   \n",
       "319                   OpenAI: GPT-4 (older v0314)  1685232000   \n",
       "320                         OpenAI: GPT-3.5 Turbo  1685232000   \n",
       "321                                 OpenAI: GPT-4  1685232000   \n",
       "\n",
       "                                           description  context_length  \\\n",
       "0    An instruction-tuned, hybrid-reasoning Mixture...           32767   \n",
       "1    Cogito v2 is a multilingual, instruction-tuned...          163840   \n",
       "2    Qwen3-30B-A3B-Thinking-2507 is a 30B parameter...          262144   \n",
       "3    Grok Code Fast 1 is a speedy and economical re...          256000   \n",
       "4    Hermes 4 70B is a hybrid reasoning model from ...          131072   \n",
       "..                                                 ...             ...   \n",
       "317  A recreation trial of the original MythoMax-L2...            6144   \n",
       "318  One of the highest performing and most popular...            4096   \n",
       "319  GPT-4-0314 is the first version of GPT-4 relea...            8191   \n",
       "320  GPT-3.5 Turbo is OpenAI's fastest model. It ca...           16385   \n",
       "321  OpenAI's flagship model, GPT-4 is a large-scal...            8191   \n",
       "\n",
       "                                          architecture  \\\n",
       "0    {'modality': 'text+image->text', 'input_modali...   \n",
       "1    {'modality': 'text->text', 'input_modalities':...   \n",
       "2    {'modality': 'text->text', 'input_modalities':...   \n",
       "3    {'modality': 'text->text', 'input_modalities':...   \n",
       "4    {'modality': 'text->text', 'input_modalities':...   \n",
       "..                                                 ...   \n",
       "317  {'modality': 'text->text', 'input_modalities':...   \n",
       "318  {'modality': 'text->text', 'input_modalities':...   \n",
       "319  {'modality': 'text->text', 'input_modalities':...   \n",
       "320  {'modality': 'text->text', 'input_modalities':...   \n",
       "321  {'modality': 'text->text', 'input_modalities':...   \n",
       "\n",
       "                                               pricing  \\\n",
       "0    {'prompt': '0.00000018', 'completion': '0.0000...   \n",
       "1    {'prompt': '0.00000125', 'completion': '0.0000...   \n",
       "2    {'prompt': '0.0000000713', 'completion': '0.00...   \n",
       "3    {'prompt': '0.0000002', 'completion': '0.00000...   \n",
       "4    {'prompt': '0.00000009329544', 'completion': '...   \n",
       "..                                                 ...   \n",
       "317  {'prompt': '0.00000045', 'completion': '0.0000...   \n",
       "318  {'prompt': '0.00000006', 'completion': '0.0000...   \n",
       "319  {'prompt': '0.00003', 'completion': '0.00006',...   \n",
       "320  {'prompt': '0.0000005', 'completion': '0.00000...   \n",
       "321  {'prompt': '0.00003', 'completion': '0.00006',...   \n",
       "\n",
       "                                          top_provider per_request_limits  \\\n",
       "0    {'context_length': 32767, 'max_completion_toke...               None   \n",
       "1    {'context_length': 163840, 'max_completion_tok...               None   \n",
       "2    {'context_length': 262144, 'max_completion_tok...               None   \n",
       "3    {'context_length': 256000, 'max_completion_tok...               None   \n",
       "4    {'context_length': 131072, 'max_completion_tok...               None   \n",
       "..                                                 ...                ...   \n",
       "317  {'context_length': 6144, 'max_completion_token...               None   \n",
       "318  {'context_length': 4096, 'max_completion_token...               None   \n",
       "319  {'context_length': 8191, 'max_completion_token...               None   \n",
       "320  {'context_length': 16385, 'max_completion_toke...               None   \n",
       "321  {'context_length': 8191, 'max_completion_token...               None   \n",
       "\n",
       "                                  supported_parameters  \n",
       "0    [frequency_penalty, include_reasoning, logit_b...  \n",
       "1    [frequency_penalty, include_reasoning, logit_b...  \n",
       "2    [frequency_penalty, include_reasoning, logit_b...  \n",
       "3    [include_reasoning, logprobs, max_tokens, reas...  \n",
       "4    [frequency_penalty, include_reasoning, logit_b...  \n",
       "..                                                 ...  \n",
       "317  [frequency_penalty, logit_bias, max_tokens, mi...  \n",
       "318  [frequency_penalty, logit_bias, max_tokens, mi...  \n",
       "319  [frequency_penalty, logit_bias, logprobs, max_...  \n",
       "320  [frequency_penalty, logit_bias, logprobs, max_...  \n",
       "321  [frequency_penalty, logit_bias, logprobs, max_...  \n",
       "\n",
       "[322 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e113ec",
   "metadata": {},
   "source": [
    "# Benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6995a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring OWID CSV for 'ai_vs_humans' -> https://ourworldindata.org/grapher/test-scores-ai-capabilities-relative-human-performance.csv?useColumnShortNames=true\n",
      "OWID CSV for 'ai_vs_humans' is non-redistributable; not available for download.\n",
      "\n",
      "Done.\n",
      "Saved files:\n",
      "  • /Users/thorwhalen/.config/aix/model_info/livebench_model_judgment.parquet\n",
      "  • /Users/thorwhalen/.config/aix/model_info/owid_ai_vs_humans.chart.json\n",
      "OWID CSV for 'ai_vs_humans' is non-redistributable; not available for download.\n",
      "\n",
      "Done.\n",
      "Saved files:\n",
      "  • /Users/thorwhalen/.config/aix/model_info/livebench_model_judgment.parquet\n",
      "  • /Users/thorwhalen/.config/aix/model_info/owid_ai_vs_humans.chart.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download current benchmark data for LLMs from:\n",
    "  1) LiveBench leaderboard judgments (Parquet)\n",
    "  2) Our World in Data AI capabilities test scores (CSV/JSON)\n",
    "\n",
    "Uses graze utilities for robust URL -> file downloads.\n",
    "Encapsulates logic in two functions: acquire_livebench_data and acquire_owid_data.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List\n",
    "from functools import partial\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "from aix.util import model_info_dir\n",
    "\n",
    "# graze helpers\n",
    "from graze.base import url_to_file_download, return_filepath\n",
    "\n",
    "# --------- Config ---------\n",
    "LIVEBENCH_PARQUET_URL = (\n",
    "    \"https://huggingface.co/datasets/livebench/model_judgment/\"\n",
    "    \"resolve/main/data/leaderboard-00000-of-00001.parquet\"\n",
    ")\n",
    "\n",
    "# Global: whether to force-refresh downloads even if files exist\n",
    "REFRESH = False\n",
    "\n",
    "\n",
    "def acquire_livebench_data(model_dir: Path, *, refresh: Optional[bool] = None) -> Optional[Path]:\n",
    "    if refresh is None:\n",
    "        refresh = REFRESH\n",
    "\n",
    "    lb_path = model_dir / \"livebench_model_judgment.parquet\"\n",
    "\n",
    "    if lb_path.exists() and not refresh:\n",
    "        return lb_path\n",
    "\n",
    "    print(f\"Acquiring LiveBench to: {lb_path}\")\n",
    "\n",
    "    try:\n",
    "        ret = url_to_file_download(\n",
    "            LIVEBENCH_PARQUET_URL,\n",
    "            filepath=str(lb_path),\n",
    "            overwrite=bool(refresh),\n",
    "            return_func=return_filepath,\n",
    "        )\n",
    "        if not ret:\n",
    "            print(\"LiveBench: download helper returned nothing\")\n",
    "            return None\n",
    "        lb_file = Path(ret)\n",
    "        if lb_file.exists():\n",
    "            print(f\"✓ LiveBench: {lb_file.name} ({lb_file.stat().st_size:,} bytes)\")\n",
    "            return lb_file\n",
    "        else:\n",
    "            print(\"LiveBench: file does not exist after download attempt\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"!!! LiveBench download failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---- Run acquisition ----\n",
    "model_info_path_obj = Path(model_info_dir)\n",
    "\n",
    "lb_file = acquire_livebench_data(model_info_path_obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyckup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6fbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
